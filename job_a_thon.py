# -*- coding: utf-8 -*-
"""Job-a-Thon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HFCIOYQFi5elHKEqZ9iU49FbV3NXGyZn
"""

import pandas as pd
import seaborn as sns
import numpy as np 
import matplotlib.pyplot as plt

train=pd.read_csv("/content/train_s3TEQDk.csv")
train.info()
sml=train.corr()
sns.heatmap(sml)

print(train.shape)
print(train.describe)

#checking for null values in training dataset 
train.isnull().sum()
train_data=train.dropna()
train_data.isnull().sum()

# checking for null values in the testing dataset 
print("for test")
test=pd.read_csv("/content/test_mSzZ8RL.csv")
print(test.head())
test.fillna(method='ffill',inplace=True)
test.isnull().sum()
test_data=test
#test_data.isnull().sum()

#checking if the data is balanced or not 
#this shows that most of the data is of lead_0 of approx 97443 and lead_1 of 17845
print(train_data.groupby(["Is_Lead"]).count())
#general plot of the lead_0 and lead_1
sns.countplot(x='Is_Lead', data=train_data)

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
train_data["Gender"]=le.fit_transform(train_data["Gender"])
train_data["Occupation"]=le.fit_transform(train_data["Occupation"])
train_data["Channel_Code"]=le.fit_transform(train_data["Channel_Code"])
train_data["Vintage"]=le.fit_transform(train_data["Vintage"])
train_data["Credit_Product"]=le.fit_transform(train_data["Credit_Product"])
train_data["Region_Code"]=le.fit_transform(train_data["Region_Code"])
train_data["Is_Lead"]=le.fit_transform(train_data["Is_Lead"])
train_data["Is_Active"]=le.fit_transform(train_data["Is_Active"])
train_data["ID"]=le.fit_transform(train_data["ID"])
train_data["Age"]=le.fit_transform(train_data["Age"])

test_data["Gender"]=le.fit_transform(test_data["Gender"])
test_data["Occupation"]=le.fit_transform(test_data["Occupation"])
test_data["Channel_Code"]=le.fit_transform(test_data["Channel_Code"])
test_data["Vintage"]=le.fit_transform(test_data["Vintage"])
test_data["Credit_Product"]=le.fit_transform(test_data["Credit_Product"])
test_data["Region_Code"]=le.fit_transform(test_data["Region_Code"])
test_data["Is_Active"]=le.fit_transform(test_data["Is_Active"])
#test_data["ID"]=le.fit_transform(test_data["ID"])
test_data["Age"]=le.fit_transform(test_data["Age"])
test_c=test_data.copy()
test_c.drop(columns="ID",axis=1,inplace=True)

X=train_data.drop(["Is_Lead"],axis=1)
y=train_data["Is_Lead"]
X.drop(columns="ID",axis=1,inplace=True)
train_data.dtypes

from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

!pip install catboost
from sklearn import linear_model
from catboost import CatBoostClassifier
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)

np.random.seed(3)

model05=CatBoostClassifier(eval_metric="AUC", depth=10, iterations= 100, l2_leaf_reg= 9, learning_rate= 0.1)

model05.fit(X_train,y_train)

print(model05.score(X_train,y_train))
ypred05=model05.predict(X_test)
print(ypred05)
cm05=confusion_matrix(y_test,ypred05)
print(cm05)
acc05=metrics.accuracy_score(y_test,ypred05)
print(acc05)

ypred_prob05=model05.predict_proba(X_test)[:,1]
ypred_prob05
fpr5,tpr5,threshold = metrics.roc_curve(y_test, model05.predict_proba(X_test)[:,1])
auc05 = metrics.roc_auc_score(y_test,ypred_prob05)
plt.plot(fpr5,tpr5,label="data , auc="+str(auc05))
plt.legend(loc=4)
plt.show()

prediction05=model05.predict_proba(test_c)
submission= pd.DataFrame()
submission["ID"] = test["ID"]
submission["Is_Lead"] = prediction05[:,1]
submission.to_csv("submission.csv", index=False)